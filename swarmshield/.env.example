# -----------------------------------------------------------------------
# SwarmShield environment template
# Copy this file to .env and fill in real values:
#   cp .env.example .env
# -----------------------------------------------------------------------

# â”€â”€ LLM â€” REQUIRED to run kickoff() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Option A: Grok (xAI) â€” recommended, used by both CrewAI orchestration
#           AND the existing LLMClient enrichment layer in Scout/Analyzer/Evolver
XAI_API_KEY=your_xai_api_key_here

# Option B: OpenAI (or any OpenAI-compatible provider)
# Uncomment and fill in if you prefer OpenAI over Grok.
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL_NAME=gpt-4o-mini
# OPENAI_BASE_URL=                   # leave blank for standard OpenAI

# â”€â”€ LLM model settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LLM_MODEL=grok-2-1212
LLM_TEMPERATURE=0.0

# â”€â”€ Live / dry-run mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LIVE_MODE=false   â†’ responder simulates actions (default, safe for demos)
# LIVE_MODE=true    â†’ responder applies real iptables rules (requires root)
LIVE_MODE=false

# â”€â”€ Responder service configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COORDINATOR_IP=192.168.1.100
HONEYPOT_IP=192.168.1.99
RESPONDER_PORT=5003
RESPONDER_ID=responder-1

# â”€â”€ Auto-unblock window (Responder background loop) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AUTO_UNBLOCK_SECONDS takes priority over AUTO_UNBLOCK_MINUTES; default 300
AUTO_UNBLOCK_SECONDS=300
# AUTO_UNBLOCK_MINUTES=5

# â”€â”€ Pre-emptive action gates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PREEMPTIVE_CONFIDENCE_GATE=0.40
CONFIRMED_CONFIDENCE_GATE=0.60
PREEMPTIVE_EXPIRE_SECONDS=60
PREEMPTIVE_RATE_LIMIT_PPS=100
# â”€â”€ Human-in-the-loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Two complementary approval layers:
#
# Layer 1 (per-action, inside tool):
#   HUMAN_APPROVAL=true â†’ before every responder action (block/quarantine/etc.)
#   the tool prints the IP, action and confidence, then waits for y/n/abort.
#   Works in ALL modes (demo, batch, interactive, MCP).
#
# Layer 2 (per-task, CrewAI level):
#   HUMAN_APPROVAL=true also sets human_input=True on the Responder task.
#   After the task runs CrewAI shows its output and asks for operator feedback
#   before execution continues to the Evolver task.
#
# Set to false (default) in automated / CI environments.
HUMAN_APPROVAL=false

# â”€â”€ Transparency / observability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Real-time agent thought process + tool calls printed during kickoff.
# TRANSPARENCY_CONSOLE=true   â†’ colour-coded terminal output  (default: true)
# TRANSPARENCY_LOG=true       â†’ append JSON-Lines to TRANSPARENCY_LOG_FILE  (default: true)
# TRANSPARENCY_LOG_FILE=path  â†’ where to write the log  (default: transparency.log)
#
# Every agent step surfaces:
#   â€¢ Agent role + step number
#   â€¢ ðŸ’­ Thought  â€” the agent's internal reasoning
#   â€¢ ðŸ”§ Tool     â€” which tool it called and with what input
#   â€¢ ðŸ“¥ Result   â€” what the tool returned
#   â€¢ A2A bus events from all 6 topics shown inline
TRANSPARENCY_CONSOLE=true
TRANSPARENCY_LOG=true
TRANSPARENCY_LOG_FILE=transparency.log

# â”€â”€ Honeypot bridge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Starts the HoneypotBridge Flask server on HONEYPOT_BRIDGE_PORT (default 5001).
# Only needed if you have a partner honeypot sending POST /honeypot_event data.
HONEYPOT_BRIDGE_ENABLED=false
HONEYPOT_BRIDGE_HOST=0.0.0.0
HONEYPOT_BRIDGE_PORT=5001
